{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df189d59-fcee-4aa1-8cb4-86b1e4f1fe35",
   "metadata": {},
   "source": [
    "# 言語処理100本ノック\n",
    "## 説明\n",
    "* Githubで公開されている問題を解いていく\n",
    "  * https://github.com/nlp100/nlp100.github.io/blob/develop/ja/ch01.md\n",
    "* 解答例はQiitaなどで公開されているものを参考にする\n",
    "  * https://qiita.com/Dukapan100knock/items/d418f2aa37b2b3d16428\n",
    "  * https://kakedashi-engineer.appspot.com/nlp100/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0cb960-f04c-471a-bd2a-d7a0c5b259f7",
   "metadata": {},
   "source": [
    "## 第1章：準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ce3b9-1bef-4092-a33c-a7bcae0d22fa",
   "metadata": {},
   "source": [
    "### 00.文字列の逆順\n",
    "文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17ee765-be94-462a-985a-8f3af7bbbc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "txt = \"stressed\"\n",
    "print(txt[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db136108-af3c-4745-b01f-ba05b011606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "# 他の解答例（ただし、回答結果の方がスマート）\n",
    "text00 = \"stressed\"\n",
    "temp = \"\"\n",
    "for i in reversed(text00):\n",
    "    temp += i\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4ca42-012f-4311-8c19-6c0c7b61c92f",
   "metadata": {},
   "source": [
    "### 01.「パタトクカシーー」\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9522100a-5aef-45d3-bf6a-04ec7a02d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "txt_01 = \"パタトクカシーー\"\n",
    "print(txt_01[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b3d223-4563-4cfa-917f-31fecae3cc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "# 他の解答例（ただし、回答結果の方がスマート）\n",
    "text01 = \"パタトクカシーー\"\n",
    "temp = \"\"\n",
    "for i, ch in enumerate(text01):\n",
    "    if i % 2 == 1:\n",
    "        continue\n",
    "    else:\n",
    "        temp += ch\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde50bed-24b6-40ec-a9c4-aff19f48222f",
   "metadata": {},
   "source": [
    "### 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f200b96a-1762-418c-8b69-26b40dad73f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "txt_02_01 = \"パトカー\"\n",
    "txt_02_02 = \"タクシー\"\n",
    "temp = \"\"\n",
    "\n",
    "for ch01, ch02 in zip(txt_02_01, txt_02_02):\n",
    "    temp += ch01\n",
    "    temp += ch02\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979da3f3-2250-46ee-b30d-dbe160625e9e",
   "metadata": {},
   "source": [
    "### 0.3円周率\n",
    "\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeaaf612-25d7-4392-aa75-ce1e10637642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nowの文字数：3\n",
      "Iの文字数：1\n",
      "needの文字数：4\n",
      "aの文字数：1\n",
      "drinkの文字数：5\n",
      "alcoholicの文字数：9\n",
      "ofの文字数：2\n",
      "courseの文字数：6\n",
      "afterの文字数：5\n",
      "theの文字数：3\n",
      "heavyの文字数：5\n",
      "lecturesの文字数：8\n",
      "involvingの文字数：9\n",
      "quantumの文字数：7\n",
      "mechanicsの文字数：9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rukk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "txt_03 = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "nltk.download('punkt')\n",
    "for word in nltk.word_tokenize(txt_03):\n",
    "    if word in ['.', ',']:\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"{word}の文字数：{len(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a7778b-0cf6-4590-92d0-6ca215d7d5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of involving: 9\n",
      "length of the: 3\n",
      "length of of: 2\n",
      "length of Now: 3\n",
      "length of lectures: 8\n",
      "length of heavy: 5\n",
      "length of course: 6\n",
      "length of a: 1\n",
      "length of alcoholic: 9\n",
      "length of after: 5\n",
      "length of mechanics: 9\n",
      "length of drink: 5\n",
      "length of I: 1\n",
      "length of need: 4\n",
      "length of quantum: 7\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "文字数カウントできたが、以下のように句読点も含まれてしまう\n",
    "drink,の文字数：6\n",
    "\n",
    "for word in txt_03.split():\n",
    "    print(f\"{word}の文字数：{len(word)}\")\n",
    "\"\"\"\n",
    "txt_03 = txt_03.replace(\",\", \" ,\")\n",
    "txt_03 = txt_03.replace(\".\", \" .\")\n",
    "\n",
    "for word in set(txt_03.split()):\n",
    "    if word in ['.', ',']:\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"length of {word}: {len(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe4204d-1f16-4b7d-bdea-dc29c5e2babc",
   "metadata": {},
   "source": [
    "### 04.元素記号\n",
    "\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1365f42e-21ee-483e-8aea-b05d351f1b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 11, 'Na': 12, 'Mi': 13, 'Al': 14, 'S': 15, 'P': 16, 'Se': 17, 'Cl': 18, 'Ar': 20, 'Ki': 21, 'Ca': 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rukk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "txt_04 = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "nltk.download('punkt')\n",
    "word_list = {}\n",
    "one_list = [0,4,5,6,7,8,14,15,18]\n",
    "for num, word in enumerate(nltk.word_tokenize(txt_04)):\n",
    "    if word in ['.', ',']:\n",
    "        continue\n",
    "    elif num in one_list:\n",
    "        word_list[f\"{word[:1]}\"] = num + 1\n",
    "    else:\n",
    "        word_list[f\"{word[:2]}\"] = num + 1\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e717d9-6026-4069-924a-0daa2ebd8f31",
   "metadata": {},
   "source": [
    "### 05.n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf92d6a-c3f6-4581-85df-5a7efc775a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'a', 'm', ' ', 'a', 'n', ' ', 'N', 'L', 'P', 'e', 'r']\n",
      "['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n",
      "[['I'], ['am'], ['an'], ['NLPer']]\n",
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "[['I', 'am', 'an'], ['am', 'an', 'NLPer']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "例）今日はいい天気ですね。\n",
    "\n",
    "単語単位）基準となる文字を1文字ずつずらす\n",
    "N=1 unigram：'今', '日', 'は', 'い', 'い', '天', '気', 'で', 'す', 'ね', '。'\n",
    "N=2 bigram：'今日', '日は', 'はい', 'いい', 'い天', '天気', '気で', 'です', 'すね', 'ね。'\n",
    "\n",
    "文字単位）形態素解析して、1単語単位でN-gramとして区切る\n",
    "N=1 unigram：'今日', 'は', 'いい', '天気', 'です', 'ね', '。'\n",
    "N=2 bigram：'今日は', 'はいい', 'いい天気', '天気です', 'ですね', 'ね。'\n",
    "\"\"\"\n",
    "import MeCab\n",
    "wakati = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "def n_gram(n, sequence):\n",
    "    return [sequence[num:num + n] for num in range(len(sequence)-n+1)]\n",
    "\n",
    "sequence = \"I am an NLPer\"\n",
    "print(n_gram(1, sequence)) #unigram\n",
    "print(n_gram(2, sequence)) #bigram\n",
    "\n",
    "def n_gram2(n, sequence):\n",
    "    return [wakati.parse(sequence).split()[num:num+n] for num in range(len(wakati.parse(sequence).split())-n+1)]\n",
    "        \n",
    "print(n_gram2(1, sequence)) #unigram\n",
    "print(n_gram2(2, sequence)) #bigram\n",
    "print(n_gram2(3, sequence)) #trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f6315-3fc6-4488-8db0-d6b01b09c65c",
   "metadata": {},
   "source": [
    "### 06.集合\n",
    "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，'se'というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3abd020d-8266-455c-9570-236eb8294e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xの集合は['pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ad', 'di', 'is', 'se']\n",
      "Yの集合は['pa', 'ar', 'ra', 'ag', 'gr', 'ra', 'ap', 'ph']\n",
      "{'ph', 'ra', 'is', 'ap', 'gr', 'di', 'se', 'ar', 'ad', 'pa', 'ag'}\n",
      "{'ap', 'pa', 'ar', 'ra'}\n",
      "{'di', 'se', 'ad', 'is'}\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "txt_06_01 = \"paraparaparadise\"\n",
    "txt_06_02 = \"paragraph\"\n",
    "\n",
    "X = n_gram(2, txt_06_01)#bigram\n",
    "Y = n_gram(2, txt_06_02)#bigram\n",
    "\n",
    "print(f\"Xの集合は{X}\")\n",
    "print(f\"Yの集合は{Y}\")\n",
    "\n",
    "#XとYの和集合\n",
    "print(set(X) | set(Y))\n",
    "#XとYの積集合\n",
    "print(set(X) & set(Y))\n",
    "#XとYの差集合\n",
    "print(set(X) - set(Y))\n",
    "#'se'というbi-gramがXおよびYに含まれるか\n",
    "print(\"se\" in X)\n",
    "print(\"se\" in Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfadb1d7-c1bd-4f69-af9e-3222b2431247",
   "metadata": {},
   "source": [
    "### 07.テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=\"気温\", z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0905250-b757-47c1-94c6-2014af0fa077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q7(x, y, z):\n",
    "    return f\"{x}時の{y}は{z}\"\n",
    "\n",
    "q7(12, \"気温\", 22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66074a4e-59d3-4aa8-bf3c-35b11afff380",
   "metadata": {},
   "source": [
    "### 08.暗号文\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "* 英小文字ならば(219 - 文字コード)の文字に置換\n",
    "* その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9817782-da36-4110-a8bd-59dfb817425d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zABy'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "def cipher(txt):\n",
    "    tmp = \"\"\n",
    "    for ch in txt:\n",
    "        if ch.islower():\n",
    "            ch = chr(219 - ord(ch))#ord()でunicodeコードポイントを返す、chr()で文字列に変換\n",
    "        tmp += ch\n",
    "    return tmp\n",
    "    \n",
    "cipher(\"aABb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8df3cb-3e2a-410f-ac91-89a6172bc0bc",
   "metadata": {},
   "source": [
    "### 09.Typoglycemia\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65d125de-8bff-41e6-b02a-cb0736796603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn'tの先頭cと末尾tを固定\n",
      "['o', 'n', \"'\", 'l', 'u', 'd']\n",
      "believeの先頭bと末尾eを固定\n",
      "['e', 'e', 'i', 'v', 'l']\n",
      "couldの先頭cと末尾dを固定\n",
      "['l', 'o', 'u']\n",
      "actuallyの先頭aと末尾yを固定\n",
      "['l', 'a', 't', 'c', 'l', 'u']\n",
      "understandの先頭uと末尾dを固定\n",
      "['d', 'e', 't', 'r', 'a', 's', 'n', 'n']\n",
      "readingの先頭rと末尾gを固定\n",
      "['n', 'i', 'e', 'a', 'd']\n",
      "phenomenalの先頭pと末尾lを固定\n",
      "['n', 'a', 'o', 'n', 'h', 'm', 'e', 'e']\n",
      "powerの先頭pと末尾rを固定\n",
      "['o', 'w', 'e']\n",
      "humanの先頭hと末尾nを固定\n",
      "['m', 'a', 'u']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "txt_09 = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "for word in txt_09.split():\n",
    "    if len(word) < 5:\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"{word}の先頭{word[:1]}と末尾{word[-1:]}を固定\")\n",
    "        print(random.sample(word[1:-1], len(word[1:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28bf13a-7493-471a-8246-550d8e860162",
   "metadata": {},
   "source": [
    "## 第2章：UNIXコマンド\n",
    "popular-names.txtは，アメリカで生まれた赤ちゃんの「名前」「性別」「人数」「年」をタブ区切り形式で格納したファイルである．以下の処理を行うプログラムを作成し，popular-names.txtを入力ファイルとして実行せよ．さらに，同様の処理をUNIXコマンドでも実行し，プログラムの実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936324c-8a16-4bad-8d59-c978c411bdc8",
   "metadata": {},
   "source": [
    "### 10.行数のカウント\n",
    "行数をカウントせよ．確認にはwcコマンドを用いよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff504ac-1f9c-43d9-a98f-c73df743c2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2780\n"
     ]
    }
   ],
   "source": [
    "with open(\"./file/popular-names.txt\") as f:\n",
    "    count = 0\n",
    "    for _ in f:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56886011-5728-4d69-9fda-135020654f58",
   "metadata": {},
   "source": [
    "### linux commandの出力\n",
    "\n",
    "wc -l popular-names.txt\n",
    "```\n",
    "（出力）\n",
    "2780 popular-names.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2a3cd-bb3a-4189-8fcd-f7cbbe3ae54d",
   "metadata": {},
   "source": [
    "### 11.タブをスペースに置換\n",
    "タブ1文字につきスペース1文字に置換せよ．確認にはsedコマンド，trコマンド，もしくはexpandコマンドを用いよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8053ab52-23ab-4b87-bcbd-6f68bbd1462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary\tF\t7065\t1880\n",
      "\n",
      "Mary F 7065 1880\n",
      "\n",
      "Anna\tF\t2604\t1880\n",
      "\n",
      "Anna F 2604 1880\n",
      "\n",
      "Emma\tF\t2003\t1880\n",
      "\n",
      "Emma F 2003 1880\n",
      "\n",
      "Elizabeth\tF\t1939\t1880\n",
      "\n",
      "Elizabeth F 1939 1880\n",
      "\n",
      "Minnie\tF\t1746\t1880\n",
      "\n",
      "Minnie F 1746 1880\n",
      "\n",
      "Margaret\tF\t1578\t1880\n",
      "\n",
      "Margaret F 1578 1880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./file/popular-names.txt\") as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        line = line.replace(\"\\t\", \" \")\n",
    "        print(line)\n",
    "        count += 1\n",
    "        if count > 5:#5行目以降は処理をストップさせた\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91220426-f511-4be3-88fe-e20e9c59bfe0",
   "metadata": {},
   "source": [
    "### linux commandの出力\n",
    "sed -e \"s/\\t/ /g\" popular-names.txt\n",
    "```\n",
    "（出力）\n",
    "Mary F 7065 1880\n",
    "Anna F 2604 1880\n",
    "Emma F 2003 1880\n",
    "Elizabeth F 1939 1880\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef2a93e-32e4-441a-b05a-6ac5507e482f",
   "metadata": {},
   "source": [
    "### 12.1列目をcol1.txtに，2列目をcol2.txtに保存\n",
    "各行の1列目だけを抜き出したものをcol1.txtに，2列目だけを抜き出したものをcol2.txtとしてファイルに保存せよ．確認にはcutコマンドを用いよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d903e7a3-f69c-4bc1-bab3-8f8b174db53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./file/popular-names.txt\") as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        if count == 0:\n",
    "            with open(\"./output/col1.txt\", mode='w') as f:\n",
    "                f.write(line)\n",
    "        elif count == 1:\n",
    "            with open(\"./output/col2.txt\", mode='w') as f:\n",
    "                f.write(line)\n",
    "        elif count > 5:#5行目以降は処理をストップさせた\n",
    "            break\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
